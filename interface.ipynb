{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/namyaagrawal03/Insurance_fraud/blob/main/interface.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pl-sB_nRM16b"
      },
      "outputs": [],
      "source": [
        "!pip install --upgrade lida\n",
        "!pip install --upgrade fastapi\n",
        "!pip install --upgrade pydantic\n",
        "!pip install --upgrade pydantic-core\n",
        "!pip install --upgrade tensorflow-probability"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90j7d2Vtk0Rp",
        "outputId": "f15fdfbf-8f8a-4b38-d9ea-532bfb0cbcca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting typing-extensions==3.10.0.2\n",
            "  Using cached typing_extensions-3.10.0.2-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: typing-extensions\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.9.0\n",
            "    Uninstalling typing_extensions-4.9.0:\n",
            "      Successfully uninstalled typing_extensions-4.9.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sqlalchemy 2.0.23 requires typing-extensions>=4.2.0, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "arviz 0.15.1 requires typing-extensions>=4.1.0, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "chex 0.1.7 requires typing-extensions>=4.2.0; python_version < \"3.11\", but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "fastapi 0.108.0 requires typing-extensions>=4.8.0, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "flax 0.7.5 requires typing-extensions>=4.2, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "gradio 4.12.0 requires typing-extensions~=4.0, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "gradio-client 0.8.0 requires typing-extensions~=4.0, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "ibis-framework 6.2.0 requires typing-extensions<5,>=4.3.0, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "librosa 0.10.1 requires typing-extensions>=4.1.1, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "openai 1.6.1 requires typing-extensions<5,>=4.7, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "polars 0.17.3 requires typing_extensions>=4.0.1; python_version < \"3.11\", but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "pydantic 2.5.3 requires typing-extensions>=4.6.1, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "pydantic-core 2.14.6 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "python-utils 3.8.1 requires typing-extensions>3.10.0.2, but you have typing-extensions 3.10.0.2 which is incompatible.\n",
            "uvicorn 0.25.0 requires typing-extensions>=4.0; python_version < \"3.11\", but you have typing-extensions 3.10.0.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed typing-extensions-3.10.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install typing-extensions==3.10.0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31xKnGEnM_sG"
      },
      "outputs": [],
      "source": [
        "!pip install gradio -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UfTnxdRQNAYv"
      },
      "outputs": [],
      "source": [
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XjaAG2wGNO59",
        "outputId": "48d049cc-4b4d-4c0a-a3b7-c73062f7c2b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import joblib\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "rfc = joblib.load('/content/drive/MyDrive/Colab Notebooks/trained_model.pkl')\n",
        "scaler = joblib.load('/content/drive/MyDrive/Colab Notebooks/scaler_filename.pkl')\n",
        "preprocessor = joblib.load('/content/drive/MyDrive/Colab Notebooks/preprocessor.joblib')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwkmdoNQlFxI"
      },
      "outputs": [],
      "source": [
        "def predict_fraud(Make, AccidentArea, Sex, Age, MaritalStatus, PolicyType,\n",
        "       VehiclePrice, Deductible, DriverRating, PastNumberOfClaims,\n",
        "       AgeOfVehicle, PoliceReportFiled, WitnessPresent, AgentType,\n",
        "       NumberOfCars):\n",
        "\n",
        "    # Create test data as a DataFrame\n",
        "    test_data = pd.DataFrame({\n",
        "        'Make': [Make],\n",
        "        'AccidentArea': [AccidentArea],\n",
        "        'Sex': [Sex],\n",
        "        'Age': [Age],\n",
        "        'MaritalStatus': [MaritalStatus],\n",
        "        'PolicyType': [PolicyType],\n",
        "        'VehiclePrice': [VehiclePrice],\n",
        "        'Deductible': [Deductible],\n",
        "        'DriverRating': [DriverRating],\n",
        "        'PastNumberOfClaims': [PastNumberOfClaims],\n",
        "        'AgeOfVehicle': [AgeOfVehicle],\n",
        "        'PoliceReportFiled': [PoliceReportFiled],\n",
        "        'WitnessPresent': [WitnessPresent],\n",
        "        'AgentType': [AgentType],\n",
        "        'NumberOfCars': [NumberOfCars]\n",
        "    })\n",
        "    # Assuming test_data is your DataFrame with categorical columns\n",
        "    categorical_cols = test_data[['Make', 'AccidentArea', 'Sex', 'MaritalStatus', 'PolicyType',\n",
        "                                'VehiclePrice', 'PastNumberOfClaims', 'AgeOfVehicle',\n",
        "                                'PoliceReportFiled', 'WitnessPresent', 'AgentType', 'NumberOfCars']]\n",
        "\n",
        "# Assuming you have new_data which has similar categorical columns\n",
        "    X_processed = preprocessor.transform(categorical_cols)\n",
        "    ohe_column_names = preprocessor.named_transformers_['cat']['encoder'].get_feature_names_out(categorical_cols.columns)\n",
        "\n",
        "# Convert the sparse matrix to a DataFrame with column names\n",
        "    X_processed = pd.DataFrame.sparse.from_spmatrix(X_processed, columns=ohe_column_names)\n",
        "\n",
        "\n",
        "# Now, new_data_encoded has the same one-hot encoding as the loaded_categorical_cols\n",
        "\n",
        "    numerical_cols = test_data[['Age', 'Deductible', 'DriverRating']]\n",
        "\n",
        "    # Select numerical columns\n",
        "    x = pd.concat([numerical_cols.reset_index(drop=True), X_processed.reset_index(drop=True)], axis=1)\n",
        "\n",
        "    x[[ 'Age', 'Deductible',  'DriverRating']]=scaler.transform(x[['Age', 'Deductible',  'DriverRating']])\n",
        "\n",
        "\n",
        "    # Combine numerical and categorical columns\n",
        "\n",
        "    predicted_label = rfc.predict(x)\n",
        "\n",
        "    if predicted_label[0] == 1:\n",
        "        output_label = \"Fraud Detected\"\n",
        "    else:\n",
        "        output_label = \"No Fraud Detected\"\n",
        "    return output_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 730
        },
        "id": "QuzisgeY6CYR",
        "outputId": "ff7e51db-2315-405d-997b-f863ab24d3f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://2e27a03b8ff3b08f37.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://2e27a03b8ff3b08f37.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/queueing.py\", line 489, in call_prediction\n",
            "    output = await route_utils.call_process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/route_utils.py\", line 232, in call_process_api\n",
            "    output = await app.get_blocks().process_api(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1561, in process_api\n",
            "    result = await self.call_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/blocks.py\", line 1179, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/to_thread.py\", line 33, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 877, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py\", line 807, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/utils.py\", line 678, in wrapper\n",
            "    response = f(*args, **kwargs)\n",
            "  File \"<ipython-input-6-310660eb0336>\", line 30, in predict_fraud\n",
            "    X_processed = preprocessor.transform(categorical_cols)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 800, in transform\n",
            "    Xs = self._fit_transform(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/compose/_column_transformer.py\", line 658, in _fit_transform\n",
            "    return Parallel(n_jobs=self.n_jobs)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1863, in __call__\n",
            "    return output if self.return_generator else list(output)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1792, in _get_sequential_output\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 876, in _transform_one\n",
            "    res = transformer.transform(X)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\", line 658, in transform\n",
            "    Xt = transform.transform(Xt)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\", line 140, in wrapped\n",
            "    data_to_wrap = f(self, X, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py\", line 917, in transform\n",
            "    X_int, X_mask = self._transform(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py\", line 166, in _transform\n",
            "    diff, valid_mask = _check_unknown(Xi, self.categories_[i], return_mask=True)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_encode.py\", line 263, in _check_unknown\n",
            "    values_set = set(values)\n",
            "TypeError: unhashable type: 'list'\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:768: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import gradio as gr\n",
        "\n",
        "# Define the dropdowns\n",
        "dropdowns = [\n",
        "    gr.Dropdown(\n",
        "        ['Pontiac', 'Toyota', 'Saturn', 'Ferrari', 'Jaguar', 'VW', 'Lexus', 'Honda', 'Ford', 'Accura', 'BMW', 'Mazda', 'Nisson', 'Chevrolet', 'Mercury', 'Porche', 'Mecedes', 'Saab', 'Dodge'], label=\"Make of the Vehicle\"\n",
        "    ),\n",
        "    gr.Dropdown(\n",
        "        ['Urban', 'Rural'], label=\"Accident Area\"\n",
        "    ),\n",
        "    gr.Dropdown(\n",
        "        ['Male', 'Female'], label=\"Sex\"\n",
        "    ),\n",
        "    gr.Dropdown(\n",
        "        ['16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37',\n",
        "         '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49', '50', '51', '52', '53', '54', '55', '56', '57', '58', '59','60', '61',\n",
        "         '62', '63', '64', '65', '66', '67', '68', '69', '70', '71', '72', '73', '74', '75', '76', '77', '78','79', '80'], label=\"Age\"\n",
        "    ),\n",
        "    gr.Dropdown(\n",
        "        ['Single',  'Married', 'Divorced', 'Widow'], label=\"Marital Status\"\n",
        "    ),\n",
        "    gr.Dropdown(\n",
        "        ['Sedan - Liability', 'Sport - Collision', 'Sport - All Perils', 'Utility - All Perils', 'Sport - Liability', 'Utility - Liability',\n",
        "         'Sedan - All Perils', 'Utility - Collision', 'Sedan - Collision'], label=\"Policy Type\"\n",
        "    ),\n",
        "    gr.Dropdown(\n",
        "        ['less than 20000', '20000 to 29000' ,'30000 to 39000',  '40000 to 59000',  '60000 to 69000',  'more than 69000' ], label=\"Price of the Vehicle\"\n",
        "    ),\n",
        "     gr.Dropdown(\n",
        "        ['300' ,'400', '500', '700'], label=\"Deductible Amount\", info=\"Select the closest amount\"\n",
        "    ),\n",
        "    gr.Dropdown(\n",
        "        ['1', '2', '3', '4'], label=\"Driver Rating\"\n",
        "    ),\n",
        "     gr.Dropdown(\n",
        "        [ 'none', '1', '2 to 4', 'more than 4'], label=\"Past Number of Claims\"\n",
        "    ),\n",
        "     gr.Dropdown(\n",
        "        ['new',  '2 years',  '3 years',  '4 years', '5 years',  '6 years',  '7 years', 'more than 7'], label=\"Age of the Vehicle\"\n",
        "    ),\n",
        "     gr.Dropdown(\n",
        "        [ 'Yes', 'No'], label=\"Was a police report filed?\"\n",
        "    ),\n",
        "    gr.Dropdown(\n",
        "        [ 'Yes', 'No'], label=\"Was there any witness present?\"\n",
        "    ),\n",
        "    gr.Dropdown(\n",
        "        ['Internal', 'External'], label=\"Agent Type\"\n",
        "    ),\n",
        "    gr.Dropdown(\n",
        "        ['1 vehicle','2 vehicles',  '3 to 4', '5 to 8', 'more than 8'], label=\"Number of cars owned\"\n",
        "    )\n",
        "\n",
        "]\n",
        "\n",
        "Gradio interface with custom layout\n",
        "interface = gr.Interface(\n",
        "    fn=predict_fraud,  # Replace with your prediction function\n",
        "    inputs=dropdowns,\n",
        "    outputs=\"text\",\n",
        "\n",
        ")\n",
        "interface.launch(debug=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asfyb-sO8Y4I"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMYDcOvzz/bfSA8M+4sJr3s",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}